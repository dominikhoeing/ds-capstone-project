{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import shutil\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                         value\n",
      "parameter                                                     \n",
      "frac                                                         1\n",
      "random_state                                                42\n",
      "use_white_line_cropping                                   True\n",
      "use_logo_cropping                                         True\n",
      "use_padding                                               True\n",
      "channels_number                                              1\n",
      "use_augmentation                                         False\n",
      "low_classes                                        [bird, hog]\n",
      "data_folder                                            ../data\n",
      "temp_folder                                       ../data/temp\n",
      "input_train_folder                      ../data/train_features\n",
      "input_test_folder                        ../data/test_features\n",
      "label_csv                             ../data/train_labels.csv\n",
      "train_features_csv                  ../data/train_features.csv\n",
      "test_features_csv                    ../data/test_features.csv\n",
      "output_train_and_val_folder         ../data/temp/train_and_val\n",
      "output_test_folder                           ../data/temp/test\n",
      "output_train_label_csv           ../data/temp/train_labels.csv\n",
      "output_val_label_csv               ../data/temp/val_labels.csv\n",
      "output_train_features_csv      ../data/temp/train_features.csv\n",
      "output_val_features_csv          ../data/temp/val_features.csv\n",
      "output_test_features_csv        ../data/temp/test_features.csv\n",
      "results_csv_path             ../data/temp/test_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "param = {}\n",
    "\n",
    "# if we want to try one part of our dataset\n",
    "param['frac'] = 1 \n",
    "param['random_state'] = 42 # for part of dataset and train_test_split\n",
    "\n",
    "param['use_white_line_cropping'] = True         # removes 16 pixels at the bottom if its white\n",
    "param['use_logo_cropping'] = True               # removes the orange logo in the bottom left corner\n",
    "param['use_padding'] = True                     # it makes photos look square due to black borders at the top and bottom \n",
    "param['channels_number'] = 1                    # 3 = RGB, 1 = black & white after cropping the orange logo\n",
    "param['use_augmentation'] = False\n",
    "param['low_classes'] = ['bird', 'hog']          # for augmentation\n",
    "\n",
    "param['data_folder'] = '../data'                # if it's the same folder use '.'\n",
    "param['temp_folder'] = os.path.join(data_folder, 'temp') \n",
    "\n",
    "# Check if temp folder alredy exists and delete it to have only files from this session\n",
    "if os.path.exists(temp_folder):\n",
    "    #Delete the directory along with its contents\n",
    "    shutil.rmtree(temp_folder)\n",
    "# create empty temp folder\n",
    "os.makedirs(temp_folder)\n",
    "\n",
    "# Set paths for input data folders\n",
    "param['input_train_folder'] = os.path.join(param['data_folder'], 'train_features')\n",
    "param['input_test_folder'] = os.path.join(param['data_folder'], 'test_features')\n",
    "param['label_csv'] = os.path.join(param['data_folder'], 'train_labels.csv')\n",
    "param['train_features_csv'] = os.path.join(param['data_folder'], 'train_features.csv')\n",
    "param['test_features_csv'] = os.path.join(param['data_folder'], 'test_features.csv')\n",
    "\n",
    "# Set paths for output data folders\n",
    "param['output_train_and_val_folder'] = os.path.join(param['temp_folder'], 'train_and_val') # if we don't do any augmentation\n",
    "param['output_test_folder'] = os.path.join(param['temp_folder'], 'test')\n",
    "\n",
    "# Set paths for output label files\n",
    "param['output_train_label_csv'] = os.path.join(param['temp_folder'], 'train_labels.csv')\n",
    "param['output_val_label_csv'] = os.path.join(param['temp_folder'], 'val_labels.csv')\n",
    "\n",
    "# Set paths for output feature files\n",
    "param['output_train_features_csv'] = os.path.join(param['temp_folder'], 'train_features.csv')\n",
    "param['output_val_features_csv'] = os.path.join(param['temp_folder'], 'val_features.csv')\n",
    "param['output_test_features_csv'] = os.path.join(param['temp_folder'], 'test_features.csv')\n",
    "\n",
    "# Set path to save the results\n",
    "param['results_csv_path'] = os.path.join(param['temp_folder'], 'test_predictions.csv')\n",
    "\n",
    "\n",
    "\n",
    "# Create variables and assign values. It means we can use for example    batch_size = 32    low_classes = ['bird', 'hog']\n",
    "for key, value in param.items():\n",
    "    globals()[key] = value\n",
    "\n",
    "\n",
    "# Convert dictionary to DataFrame with parameters as index and save to csv\n",
    "df_param = pd.DataFrame(list(param.items()), columns=['parameter', 'value']).set_index('parameter')\n",
    "df_param.to_csv('../data/temp/parameters.csv', index=True)\n",
    "\n",
    "\n",
    "#We should use it in models notebook to have the same parameters\n",
    "\n",
    "# # Convert 'value' column to appropriate data types\n",
    "# def convert_value(value):\n",
    "#     try:\n",
    "#         return int(value)\n",
    "#     except ValueError:\n",
    "#         try:\n",
    "#             return float(value)\n",
    "#         except ValueError:\n",
    "#             return value  # Return as string if it can't be converted to number\n",
    "\n",
    "# param_path = '../data/temp/parameters.csv'\n",
    "\n",
    "# if os.path.exists(param_path):\n",
    "#     df_param = pd.read_csv(param_path)\n",
    "#     df_param.set_index('parameter', inplace=True)\n",
    "#     # Apply the conversion function to the 'value' column\n",
    "#     df_param['value'] = df_param['value'].apply(convert_value)\n",
    "#     param = df_param.to_dict()['value']\n",
    "\n",
    "# else:\n",
    "#     param = {}\n",
    "\n",
    "#     # if we want to try one part of our dataset\n",
    "#     param['frac'] = 0.1 \n",
    "#     param['random_state'] = 1 \n",
    "    \n",
    "#     param['data_folder'] = '../data' # if this file and folders train_features and test_features are in the same folder use '.'\n",
    "#     param['label_csv'] = os.path.join(data_folder, 'train_labels.csv')\n",
    "#     param['train_features_csv'] = os.path.join(data_folder, 'train_features.csv')\n",
    "#     param['test_features_csv'] = os.path.join(data_folder, 'test_features.csv')\n",
    "\n",
    "#     # Convert dictionary to DataFrame with parameters as index and save to csv\n",
    "#     df_param = pd.DataFrame(list(param.items()), columns=['parameter', 'value']).set_index('parameter')\n",
    "\n",
    "\n",
    "# # Create variables and assign values\n",
    "# for key, value in param.items():\n",
    "#     globals()[key] = value\n",
    "# print(df_param)\n",
    "\n",
    "\n",
    "print(df_param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of white color\n",
    "def is_white_color(color, threshold=230):\n",
    "    # Check if color is close to white within the given threshold\n",
    "    return all(c >= threshold for c in color)\n",
    "\n",
    "\n",
    "# Adjust threshold based on what is considered \"close to white\"\n",
    "def crop_white_bottom_from_image(img, check_hight=8, check_width=10, start_from=60, threshold=230):\n",
    "    width, height = img.size\n",
    "    # Define the region to check for white color\n",
    "    box = (start_from, height - check_hight, start_from + check_width, height)\n",
    "    region = img.crop(box)\n",
    "    # Convert the region to a NumPy array for easy processing\n",
    "    region_np = np.array(region)\n",
    "    # Check if all pixels in the region are close to white\n",
    "    white_pixels = np.apply_along_axis(is_white_color, 1, region_np)\n",
    "    \n",
    "    if np.all(white_pixels):\n",
    "        # Crop the bottom 16 pixels\n",
    "        img = img.crop((0, 0, width, height - check_hight - 8))\n",
    "    return img\n",
    "\n",
    "\n",
    "def padding_images(img):\n",
    "    # Determine the maximum size (either width or height)\n",
    "    max_size = max(img.width, img.height)\n",
    "    \n",
    "    # Calculate padding needed to center the image within a square of size max_size x max_size\n",
    "    delta_width = max_size - img.width\n",
    "    delta_height = max_size - img.height\n",
    "    padding = (\n",
    "        delta_width // 2,  # Left padding\n",
    "        delta_height // 2,  # Top padding\n",
    "        delta_width - (delta_width // 2),  # Right padding\n",
    "        delta_height - (delta_height // 2)  # Bottom padding\n",
    "    )\n",
    "    \n",
    "    # Add padding and create a new image with a black background\n",
    "    return ImageOps.expand(img, padding, fill=0)\n",
    "\n",
    "\n",
    "def set_channel(img,channel):\n",
    "    if channel == 3:\n",
    "        img = img.convert('RGB')\n",
    "    else:\n",
    "        # Convert to grayscale\n",
    "        img = img.convert('L')\n",
    "    return img\n",
    "\n",
    "\n",
    "def is_bright_orange(rgb):\n",
    "    r, g, b = rgb\n",
    "    # Approximate boundaries for bright orange color in RGB\n",
    "    return (r > 180 and 50 < g < 200 and b < 110)\n",
    "\n",
    "def replace_logo_with_neighboring_colors(img,search_area_height=50, search_area_width=50):\n",
    "    #Get the image dimensions\n",
    "    width, height = img.size\n",
    "    pixels = img.load()\n",
    "\n",
    "    # List to store coordinates of orange pixels\n",
    "    orange_points = []\n",
    "\n",
    "    # Iterate over the bottom-left 50x50 rectangle\n",
    "    for x in range(search_area_width):\n",
    "        for y in range(height - search_area_height, height):\n",
    "            if is_bright_orange(pixels[x, y]):\n",
    "                orange_points.append((x, y))\n",
    " \n",
    "    # If orange pixels are found\n",
    "    if orange_points:\n",
    "        # Find the top-right orange point and take some points more\n",
    "        max_orange_x = max(x for x,y in orange_points)+3\n",
    "        min_orange_y = min(y for x,y in orange_points)-5\n",
    "\n",
    "        # Replace logo with vertical lines. Color is like color of pixel above\n",
    "        for x in range(max_orange_x):\n",
    "            color = pixels[x, min_orange_y-1]\n",
    "            for y in range(min_orange_y, height):\n",
    "                pixels[x, y] = color\n",
    "    return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation for birds and hogs\n",
    "\n",
    "def augment_class_images(input_folder, train_df, target_classes):\n",
    "    # Calculate the average number of images across all classes\n",
    "    class_counts = train_df.drop(columns=['id']+target_classes).sum(axis=0)\n",
    "    avg_count = int(class_counts.mean())\n",
    "\n",
    "    # Create a generator for data augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=10,       # Rotations\n",
    "        width_shift_range=0.1,   # Width shifts\n",
    "        height_shift_range=0.1,  # Height shifts\n",
    "        shear_range=0.1,         # Shear angle shifts\n",
    "        zoom_range=0.1,          # Zooming\n",
    "        horizontal_flip=True,    # Horizontal flipping\n",
    "        fill_mode='nearest'      # Filling new pixels after transformation\n",
    "    )\n",
    "    # Perform augmentation for each target class\n",
    "    for target_class in target_classes:\n",
    "        # Filter the dataframe for the target class\n",
    "        class_df = df[df[target_class] == 1]\n",
    "        # Calculate how many images need to be generated\n",
    "        num_images_needed = avg_count - len(class_df)\n",
    "\n",
    "        # Create output folder for the augmented images\n",
    "        output_folder = os.path.join(input_folder, target_class)#f'{target_class}_augmented')\n",
    "\n",
    "        # Check if the directory exists\n",
    "        if os.path.exists(output_folder):\n",
    "            #Delete the directory along with its contents\n",
    "            shutil.rmtree(output_folder)\n",
    "\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        for _ in range(num_images_needed): \n",
    "            random_id = class_df['id'].sample(n=1).iloc[0] \n",
    "            img_path = os.path.join(input_folder, random_id)\n",
    "            img = load_img(img_path)\n",
    "            x = img_to_array(img)  # Convert image to numpy array\n",
    "            x = x.reshape((1,) + x.shape)  # Add dimension to work with ImageDataGenerator\n",
    "            # Generate new images\n",
    "            for batch in datagen.flow(x, batch_size=1,save_to_dir=output_folder, save_prefix=target_class, save_format='jpeg'):\n",
    "                break\n",
    "           \n",
    "           \n",
    "        print(f\"Created {num_images_needed} augmented images for class '{target_class}' in folder '{output_folder}'.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_features(input_folder,output_folder,input_df=None,use_white_line_cropping=use_white_line_cropping,use_logo_cropping=use_logo_cropping,\\\n",
    "                           use_padding=use_padding,channels_number=channels_number):\n",
    "\n",
    "    # Create the new folder if it does not exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    # Iterate through each image in the source folder\n",
    "    if input_df is not None and not input_df.empty:\n",
    "        file_list = input_df['id']\n",
    "    else:\n",
    "        file_list = os.listdir(input_folder)\n",
    "        #file_list = file_list.apply(lambda x: os.path.join(input_folder, x))\n",
    "\n",
    "    i = 0    \n",
    "    for filename in file_list:\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "            with Image.open(file_path) as img:\n",
    "                img = set_channel(img,3) # to crop orange logo\n",
    "                if use_white_line_cropping:\n",
    "                    img = crop_white_bottom_from_image(img)\n",
    "                if use_logo_cropping:\n",
    "                    img = replace_logo_with_neighboring_colors(img)\n",
    "                img =  set_channel(img,channels_number)\n",
    "                if use_padding:\n",
    "                    img = padding_images(img)\n",
    "           \n",
    "                new_file_path = os.path.join(output_folder, filename)\n",
    "                img.save(new_file_path)\n",
    "                i += 1\n",
    "    print(f\"{i} rows were added in {output_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filepath</th>\n",
       "      <th>site</th>\n",
       "      <th>antelope_duiker</th>\n",
       "      <th>bird</th>\n",
       "      <th>blank</th>\n",
       "      <th>civet_genet</th>\n",
       "      <th>hog</th>\n",
       "      <th>leopard</th>\n",
       "      <th>monkey_prosimian</th>\n",
       "      <th>rodent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZJ000000</td>\n",
       "      <td>train_features/ZJ000000.jpg</td>\n",
       "      <td>S0120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZJ000001</td>\n",
       "      <td>train_features/ZJ000001.jpg</td>\n",
       "      <td>S0069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZJ000002</td>\n",
       "      <td>train_features/ZJ000002.jpg</td>\n",
       "      <td>S0009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZJ000003</td>\n",
       "      <td>train_features/ZJ000003.jpg</td>\n",
       "      <td>S0008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZJ000004</td>\n",
       "      <td>train_features/ZJ000004.jpg</td>\n",
       "      <td>S0036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16483</th>\n",
       "      <td>ZJ016483</td>\n",
       "      <td>train_features/ZJ016483.jpg</td>\n",
       "      <td>S0093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16484</th>\n",
       "      <td>ZJ016484</td>\n",
       "      <td>train_features/ZJ016484.jpg</td>\n",
       "      <td>S0043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16485</th>\n",
       "      <td>ZJ016485</td>\n",
       "      <td>train_features/ZJ016485.jpg</td>\n",
       "      <td>S0089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16486</th>\n",
       "      <td>ZJ016486</td>\n",
       "      <td>train_features/ZJ016486.jpg</td>\n",
       "      <td>S0095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16487</th>\n",
       "      <td>ZJ016487</td>\n",
       "      <td>train_features/ZJ016487.jpg</td>\n",
       "      <td>S0021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16488 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                     filepath   site  antelope_duiker  bird   \n",
       "0      ZJ000000  train_features/ZJ000000.jpg  S0120              0.0   1.0  \\\n",
       "1      ZJ000001  train_features/ZJ000001.jpg  S0069              0.0   0.0   \n",
       "2      ZJ000002  train_features/ZJ000002.jpg  S0009              0.0   1.0   \n",
       "3      ZJ000003  train_features/ZJ000003.jpg  S0008              0.0   0.0   \n",
       "4      ZJ000004  train_features/ZJ000004.jpg  S0036              0.0   0.0   \n",
       "...         ...                          ...    ...              ...   ...   \n",
       "16483  ZJ016483  train_features/ZJ016483.jpg  S0093              0.0   0.0   \n",
       "16484  ZJ016484  train_features/ZJ016484.jpg  S0043              0.0   0.0   \n",
       "16485  ZJ016485  train_features/ZJ016485.jpg  S0089              0.0   0.0   \n",
       "16486  ZJ016486  train_features/ZJ016486.jpg  S0095              0.0   1.0   \n",
       "16487  ZJ016487  train_features/ZJ016487.jpg  S0021              0.0   0.0   \n",
       "\n",
       "       blank  civet_genet  hog  leopard  monkey_prosimian  rodent  \n",
       "0        0.0          0.0  0.0      0.0               0.0     0.0  \n",
       "1        0.0          0.0  0.0      0.0               1.0     0.0  \n",
       "2        0.0          0.0  0.0      0.0               0.0     0.0  \n",
       "3        0.0          0.0  0.0      0.0               1.0     0.0  \n",
       "4        0.0          0.0  0.0      1.0               0.0     0.0  \n",
       "...      ...          ...  ...      ...               ...     ...  \n",
       "16483    1.0          0.0  0.0      0.0               0.0     0.0  \n",
       "16484    0.0          0.0  0.0      1.0               0.0     0.0  \n",
       "16485    0.0          1.0  0.0      0.0               0.0     0.0  \n",
       "16486    0.0          0.0  0.0      0.0               0.0     0.0  \n",
       "16487    0.0          1.0  0.0      0.0               0.0     0.0  \n",
       "\n",
       "[16488 rows x 11 columns]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features = pd.read_csv(train_features_csv)\n",
    "df = pd.read_csv(label_csv)\n",
    "df = df_features.merge(df,on='id')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12366 rows were added in ../data/temp/train_and_val\n",
      "4122 rows were added in ../data/temp/train_and_val\n",
      "4464 rows were added in ../data/temp/test\n",
      "Train labels (12366) saved to ../data/temp/train_labels.csv\n",
      "Validation labels (4122) saved to ../data/temp/val_labels.csv\n",
      "Train features saved to ../data/temp/train_features.csv\n",
      "Validation features saved to ../data/temp/val_features.csv\n",
      "Test features saved to ../data/temp/test_features.csv\n"
     ]
    }
   ],
   "source": [
    "class_names = list(df.columns[3:])\n",
    "\n",
    "df = df.sample(frac=frac, random_state=random_state)\n",
    "\n",
    "\n",
    "# Add a full path to each image in the dataframe\n",
    "df['id'] = df['id'].apply(lambda x: x+'.jpg')#os.path.join(input_train_folder, x+'.jpg'))\n",
    "#df['id'] = df['id'].apply(lambda x: x+'.jpg')#os.path.join(dataset_folder, x+'.jpg'))\n",
    "\n",
    "# Perform stratified split based on the labels\n",
    "train_df, val_df = train_test_split(df, test_size=0.25, random_state=random_state, stratify=df[df.columns[3:]])\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_features(input_train_folder, output_train_and_val_folder, train_df)\n",
    "preprocessing_features(input_train_folder, output_train_and_val_folder, val_df)\n",
    "preprocessing_features(input_test_folder, output_test_folder)\n",
    "\n",
    "#if use_augmentation:\n",
    "    #augment_class_images(middle_train_folder, train_df, low_classes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_df['filepath'] = train_df['id'].apply(lambda x: os.path.join(output_train_and_val_folder, x))\n",
    "train_df['id'] = train_df['id'].str.replace('.jpg', '', regex=False)\n",
    "train_df.drop(columns=['filepath','site']).to_csv(output_train_label_csv, index=False)\n",
    "train_df[['id','filepath','site']].to_csv(output_train_features_csv, index=False)\n",
    "\n",
    "\n",
    "val_df['filepath'] = val_df['id'].apply(lambda x: os.path.join(output_train_and_val_folder, x))\n",
    "val_df['id'] = val_df['id'].str.replace('.jpg', '', regex=False)\n",
    "val_df.drop(columns=['filepath','site']).to_csv(output_val_label_csv, index=False)\n",
    "val_df[['id','filepath','site']].to_csv(output_val_features_csv, index=False)\n",
    "\n",
    "test_df = pd.read_csv(test_features_csv)\n",
    "test_df['filepath'] = test_df['id'].apply(lambda x: os.path.join(output_test_folder, x+'.jpg'))\n",
    "test_df.to_csv(output_test_features_csv, index=False)\n",
    "\n",
    "print(f\"Train labels ({len(train_df)}) saved to {output_train_label_csv}\")\n",
    "print(f\"Validation labels ({len(val_df)}) saved to {output_val_label_csv}\")\n",
    "\n",
    "print(f\"Train features saved to {output_train_features_csv}\")\n",
    "print(f\"Validation features saved to {output_val_features_csv}\")\n",
    "\n",
    "print(f\"Test features saved to {output_test_features_csv}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
